{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# QA/QC\n",
    " \n",
    "### What is QA/QC:\n",
    "The task of annotating the quality of collected data/observation:\n",
    "\n",
    "    - GOOD\n",
    "    - BAD\n",
    "    - SUSPECT\n",
    "    - UNKNOWN\n",
    "    \n",
    "### Why QA/QC is needed:\n",
    "\n",
    "Due to different conditions in the natural environment, observations collected by sensors may not be reliable.  \n",
    "The quality assurance and control of data collected from sensor is very important to make sure the data usability.\n",
    "\n",
    "### What are methods to annotate data with QA/QC flags:\n",
    "\n",
    "[IOOS](https://ioos.github.io/ioos_qc/resources.html) has defined standard and statistical methods to annotate quality check on ocean time-series data. As for each essential ocean variable (EoV), different set of statistical tests are recommended to ensure the quality of collected data. Please read the [mannual](https://github.com/ioos/ioos_qc/blob/main/resources/argo-quality-control-manual.pdf) and [mannual In-situ](https://cdn.ioos.noaa.gov/media/2019/08/QARTOD_Currents_Update_Second_Final.pdf)\n",
    "\n",
    "\n",
    "### Why thresholds are necessary\n",
    "\n",
    "[IOOS](https://ioos.github.io/ioos_qc/resources.html) developed a IOOS_QC [QARTOD](https://ioos.github.io/ioos_qc/examples/Qartod_Single_Test_Example.html) python package in which different statistical functions are implemented. As each statistical function requires series to observations (time-series data), as well as it requires additional parameters which are referred as thresholds. \n",
    "\n",
    "For Example:\n",
    "\n",
    "The most basic test (QARTOD function) for each EoV is `range test` where the natural range of value is used to validate the observation (data value). E.g., for sea surface temperature the global range is between -2.5 and 40.0. In this example, the lowest recorded temperature is -2.5 and the highest recorded temperature is 40.0. However, it is uncommon that temperature reaches to extreme that is why `range test` function also takes suspect threshold value to define which values can be suspect to error or warning. \n",
    "\n",
    "### What current datasets are avaiable with QA/QC annotations\n",
    "\n",
    "In CIOOS Atlantic data repository, CMAR is the only partners whose dataset are annotated with QA/QC flags. Here is the list of dataset by CMAR:\n",
    "\n",
    "1. Annapolis County\n",
    "2. Antigonish County\n",
    "3. Cape Breton County\n",
    "4. Colchester County\n",
    "5. Digby County\n",
    "6. Inverness County\n",
    "7. Lunenburg County\n",
    "8. Pictou County\n",
    "9. Queens County\n",
    "10. Richmond County\n",
    "11. Shelburne County\n",
    "12. Victoria County\n",
    "13. Yarmouth County\n",
    "\n",
    "The description related to [CMAR QC Test & Threshold](https://dempsey-cmar.github.io/cmp-data-governance/pages/qc_tests.html#fn1) are provided. The EoVs annotated in these datasets are:\n",
    "\n",
    "- dissolved oxygen\n",
    "- sea surface temperature\n",
    "- salinity\n",
    "- depth check\n",
    "\n",
    "\n",
    "### What we are trying to estimate\n",
    "\n",
    "With the help of domain expert, CMAR has defined [thresholds](res/2024-10-24_cmar_water_quality_thresholds.csv) for each EoVs with respect to QARTOD function and month. Our objective is to learn the thresholds from existing data to annotate QA/QC flags. Estimating and learning threshold from known data will help us to predict QA/QC flags for unknown data which is not annotated.  \n",
    "\n",
    "In this empirical study, we are focusing on `sea surface temperature`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4e4c62e054a58af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step#1:  Download the data as csv\n",
    "The csv file contain first column as field name and second column contains the unit of each value.\n",
    "\n",
    "## Step#2: Replacing String flag into int Flags\n",
    "By default, the raw data contains flag in String but for easy to process we replace string into integer to optimize. We save the a new file as .csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "719e7b4e683cfdd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "class QartodFlags:\n",
    "    \"\"\"Primary flags for QARTOD.\"\"\"\n",
    "    GOOD = 1\n",
    "    UNKNOWN = 2\n",
    "    SUSPECT = 3\n",
    "    FAIL = 4\n",
    "    MISSING = 9\n",
    "\n",
    "\n",
    "# TARGET EoV is SEA SURFACE TEMPERATURE\n",
    "eov_range = (-2.0, 40)\n",
    "eov_col_name = 'temperature'\n",
    "eov_flag_name = 'qc_flag_temperature'\n",
    "window_hour = 12\n",
    "min_rows_in_a_chunk = 6\n",
    "minimum_rows_for_each_group = 50\n",
    "\n",
    "\n",
    "################# REPLACE FLAGS FROM STRING TO INT FROM CSV##################\n",
    "def custom_replacement(value):\n",
    "    if value == 'Not Evaluated':\n",
    "        return QartodFlags.UNKNOWN\n",
    "    elif value == 'Pass':\n",
    "        return QartodFlags.GOOD\n",
    "    elif value == 'Suspect/Of Interest':\n",
    "        return QartodFlags.SUSPECT\n",
    "    elif value == 'Fail':\n",
    "        return QartodFlags.FAIL\n",
    "    elif math.isnan(float(value)):\n",
    "        return -1\n",
    "    else:\n",
    "        print(f\"Unknown [{value}]\")\n",
    "\n",
    "    return value\n",
    "\n",
    "csv_name = \"D://CIOOS-Full-Data/Annapolis County Water Quality Data.csv\"\n",
    "# if the file is big then process into chunks\n",
    "df_chunks = pd.read_csv(csv_name, chunksize=10000)\n",
    "columns_ = None\n",
    "header_written = False\n",
    "for df in df_chunks:\n",
    "    if columns_ is None:\n",
    "        lst_col  = list(df.columns)\n",
    "        # columns which starts with `qc_` are flag columns\n",
    "        columns_ = [col for col in lst_col if \"qc\" in col.lower()]\n",
    "    for col in columns_:\n",
    "        df[col] = df[col].apply(custom_replacement)\n",
    "\n",
    "    df.to_csv(csv_name.replace(\".csv\", \"_FlagCode.csv\") , index=False, mode='a', header= not header_written)\n",
    "    header_written = True\n",
    "\n",
    "# output: Annapolis County Water Quality Data_FlagCode.csv\n",
    "#######################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e862cf9115ec6012"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step#3: Grouping the data\n",
    "The data is collected on different stations. And each station may have installed one or more sensors. Thus we need to group data by station and sensor. \n",
    "\n",
    "In this code below, the csv `dataframe` is grouped on `station` and `sensor`. Within the data collected, we also need to validate if the collected data is from the same geographical area. That is the reason we group the location with difference of `eps=0.001`.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b65471eddff931ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def group_with_dbscan(values, eps=0.001): \n",
    "    # Convert to 2D array as required by DBSCAN\n",
    "    X = np.array(values).reshape(-1, 1)\n",
    "    db = DBSCAN(eps=eps, min_samples=1)\n",
    "    labels = db.fit_predict(X)\n",
    "    # Group values by cluster label\n",
    "    groups = []\n",
    "    for label in sorted(set(labels)):\n",
    "        group = [v for v, l in zip(values, labels) if l == label]\n",
    "        groups.append(group)\n",
    "    return groups\n",
    "\n",
    "\n",
    "csv_name = \"D://CIOOS-Full-Data/Annapolis County Water Quality Data_FlagCode.csv\"\n",
    "# lets make subdirectory\n",
    "dir__ = os.path.dirname(csv_name) # D://CIOOS-Full-Data/\n",
    "filename_ = os.path.basename(csv_name) #Annapolis County Water Quality Data_FlagCode.csv\n",
    "new_directory_name = filename_.split(\" \")[0]  #Annapolis\n",
    "save_dir_ = os.path.join(dir__, new_directory_name)\n",
    "os.makedirs(save_dir_) # D://CIOOS-Full-Data/Annapolis/\n",
    "save_name =  os.path.join( save_dir_, filename_.replace(\"_FlagCode.csv\",\"\")) \n",
    "\n",
    "\n",
    "df_ = pd.read_csv(csv_name, parse_dates=['time'], skiprows=[1])\n",
    "df_['latitude'] = df_['latitude'].astype(np.float32).round(4)\n",
    "df_['longitude'] = df_['longitude'].astype(np.float32).round(4)\n",
    "\n",
    "groups_ = df_.groupby(by=['station', 'sensor_serial_number'])\n",
    "id_ = 1\n",
    "for grp_, chunk in groups_:\n",
    "    if chunk.shape[0] < minimum_rows_for_each_group: \n",
    "        continue\n",
    "    # check if the data of more than 1 day is collected\n",
    "    d_threshold = (pd.to_datetime(chunk['time'].max()) - pd.to_datetime(chunk['time'].min())).days > 1\n",
    "    if not d_threshold:\n",
    "        continue\n",
    "\n",
    "    # checking if the data from same sensor is collected from different geographical area\n",
    "    lat_uni_ = chunk['latitude'].unique()\n",
    "    lon_uni_ = chunk['longitude'].unique()\n",
    "    a_ = lat_uni_.std()\n",
    "    b_ = lon_uni_.std()\n",
    "    if a_ > 0.001:\n",
    "        rows__ = chunk.shape[0]\n",
    "        total_rows__ = 0\n",
    "        lat_groups_ = group_with_dbscan(values=lat_uni_)\n",
    "        for j, lat_grp in enumerate(lat_groups_):\n",
    "            sub_chunk_ = chunk[ (chunk['latitude'] >= min(lat_grp)) &  (chunk['latitude'] <= max(lat_grp)) ]\n",
    "            sub_b_ = sub_chunk_['longitude'].astype(np.float32).unique()\n",
    "            assert sub_b_.std() <= 0.001, f\"many longitudes {lat_uni_}\"\n",
    "            sub_chunk_.to_csv(save_name + f\"-{id_}-{j}.csv\", index=False)\n",
    "            total_rows__ += sub_chunk_.shape[0]\n",
    "            print(save_name + f\"-{id_}-{j}.csv\")\n",
    "        assert total_rows__ == rows__, f\"LAT sub chunk rows not equal to main chunk [{lat_grp}] - [{lat_uni_}]\"\n",
    "\n",
    "    else:\n",
    "        if b_ > 0.001:\n",
    "            rows__ = chunk.shape[0]\n",
    "            total_rows__ = 0\n",
    "            lon_groups_ = group_with_dbscan(values=lon_uni_)\n",
    "            for j, lon_grp in enumerate(lon_groups_):\n",
    "                sub_chunk_ = chunk[(chunk['longitude'] >= min(lon_grp)) & (chunk['longitude'] <= max(lon_grp))]\n",
    "                sub_chunk_.to_csv(save_name + f\"-{id_}-{j}.csv\", index=False)\n",
    "                print(save_name + f\"-{id_}-{j}.csv\")\n",
    "                total_rows__ += sub_chunk_.shape[0]\n",
    "\n",
    "            assert total_rows__ == rows__, f\"LON sub chunk rows not equal to main chunk [{lon_groups_}] - [{lon_groups_}]\"\n",
    "        else:\n",
    "            chunk.to_csv(save_name+f\"-{id_}.csv\", index=False)\n",
    "    id_+=1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "712e5c17f473468b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Time-window](res/final_report_diagram.jpg)\n",
    "\n",
    "## Current Feature Set:\n",
    "1)\tRolling Standard Deviation\n",
    "2)\tPast-window mean – current value\n",
    "3)\tFuture-window mean – current value\n",
    "4)\tFuture-window mean – Past-window mean\n",
    "5)\tcurrent value – ( (lead value – lag value)  / 2)\n",
    "6)\tMonth Average Hourly Change – (lag Value – current Value)\n",
    "7)\tMonth Average Hourly Change – (lead Value – current Value)\n",
    "8)\t(Current Value – q_997) if current value > q_997 else 0\n",
    "9)\t(Current Value – q_003) if current value < q_003 else 0\n",
    "10)\t (Current Value – fwq_997) if current value > fwq_997 else 0\n",
    "11)\t(Current Value – fwq_003) if current value > fwq_003 else 0\n",
    "12)\tMonth (1 - 12)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2676faf95170e41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e60a24286894cc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
